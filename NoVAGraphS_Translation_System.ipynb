{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcEbF7YADKQR"
      },
      "source": [
        "# Librerie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u-W7NZtmC4IT"
      },
      "outputs": [],
      "source": [
        "# Installazione delle librerie necessarie con specifiche per l'uso della GPU\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.76 numpy==1.21.6 scipy==1.7.3 sentence_transformers==2.2.2 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "!pip install huggingface_hub\n",
        "!pip install openpyxl\n",
        "!pip install pandas\n",
        "!pip install langchain\n",
        "!pip install langchain-chroma\n",
        "!pip install langchain-community\n",
        "!pip install faiss-cpu\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T53WLN_xJaEp"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import spacy\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import openpyxl\n",
        "import faiss\n",
        "import difflib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pyngrok import ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0HX0U33K4zO"
      },
      "source": [
        "# Chiamata Modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bYELKaaJhJ1"
      },
      "outputs": [],
      "source": [
        "# Select LLama2 13B as the model\n",
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\"\n",
        "\n",
        "# Download the model from Hugging Face Hub\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
        "\n",
        "# Initialize the model with configuration for GPU\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2,  # Number of CPU cores\n",
        "    n_batch=512,  # Batch size, depends on GPU VRAM\n",
        "    n_gpu_layers=32  # Number of layers handled by the GPU\n",
        ")\n",
        "lcpp_llm.params.n_gpu_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DOSpyqLLBgr"
      },
      "outputs": [],
      "source": [
        "# Response generation\n",
        "def call_model(prompt):\n",
        "  response = lcpp_llm(prompt=prompt, max_tokens=4096)\n",
        "  return response[\"choices\"][0][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5lExt8jLFCi"
      },
      "source": [
        "# Vector Store Few Shots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uy6bzvYLDyF"
      },
      "outputs": [],
      "source": [
        "# Initialization of the embedding model\n",
        "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukXQVOJjLMHF"
      },
      "outputs": [],
      "source": [
        "# Input and output data examples\n",
        "inputs = [\n",
        "    \"According to your understanding of Automaton...\",\n",
        "    \"What is the final state of an automaton\",\n",
        "    \"How are transitions defined\",\n",
        "    \"How is an automaton defined\",\n",
        "    \"what are the symbols accepted by the automaton\",\n",
        "    \"nodes\",\n",
        "    \"Give me a list of the arcs\",\n",
        "    \"what is the initial stage of the automaton\",\n",
        "    \"Tell me a little bit about the automaton\",\n",
        "    \"transitions\",\n",
        "    \"q0\",\n",
        "    \"Please describe the transitions\",\n",
        "    \"which is final state\",\n",
        "    \"could be this automaton determinated\",\n",
        "    \"There is a transition between q5 and q7\",\n",
        "    \"What is q1??\",\n",
        "    \"Does it only accept 1s and 0s\",\n",
        "    \"And how about the arrows\",\n",
        "    \"What is the purpose of the automaton\",\n",
        "    \"How are your states linked together\",\n",
        "    \"what are the transitions from q4\",\n",
        "    \"What are the states connected to q0\",\n",
        "    \"What does the automaton recognize\",\n",
        "    \"How many nodes are there\",\n",
        "    \"Can you provide a representation of the automaton\",\n",
        "    \"Give me some examples of inputs and output\",\n",
        "    \"What is the output\",\n",
        "    \"Output\",\n",
        "    \"Talk me about transitions\",\n",
        "    \"what are the input symbols\",\n",
        "    \"if the input is 11100 which is the result\",\n",
        "    \"if the input is 110 which is the result\",\n",
        "    \"What are the accepted inputs\",\n",
        "    \"what are all the transictions\",\n",
        "    \"Show me the transitions of the automaton\",\n",
        "    \"What transitions does the automaton have\",\n",
        "    \"what are the final states\",\n",
        "    \"how many final states there are\",\n",
        "    \"what is its optimal spatial representation\",\n",
        "    \"What can I use finite state automata for\",\n",
        "    \"Can I use 5 states in an automaton\",\n",
        "    \"How can I define an automaton\",\n",
        "    \"What is an example of accepted string\",\n",
        "    \"What could be a minimal spatial representation for this automaton\",\n",
        "    \"which are the trasitions\",\n",
        "    \"good morning\",\n",
        "    \"how are you\",\n",
        "    \"what's up\",\n",
        "    \"maximum number of states in an automaton\",\n",
        "    \"According to your understanding of Automaton what is its optimal spatial representation\",\n",
        "    \"What is the best way to represent this automa\",\n",
        "    \"Summarise the automaton\",\n",
        "    \"What are automaton\",\n",
        "    \"start states\",\n",
        "    \"final states\",\n",
        "    \"overview of the automaton\",\n",
        "    \"how is the automaton\",\n",
        "    \"transition diagram\",\n",
        "    \"what s the number of nodes\",\n",
        "    \"is 1 a label for some arc\",\n",
        "    \"What direction are the connections between the states\",\n",
        "    \"what are the states and the connections between states\",\n",
        "    \"which are the states connected with 0\",\n",
        "    \"what are the patterns\",\n",
        "    \"what is a pattern\",\n",
        "    \"Which are the transitions from q1\",\n",
        "    \"Which are the transitions from q2\",\n",
        "]\n",
        "\n",
        "outputs = [\n",
        "    \"Tell me more about the automaton\",\n",
        "    \"What is the final state\",\n",
        "    \"What are the transitions\",\n",
        "    \"What is an automaton\",\n",
        "    \"What is the alphabet\",\n",
        "    \"Tell me more about states\",\n",
        "    \"What are the arcs\",\n",
        "    \"What is the initial state\",\n",
        "    \"Describe me briefly the automaton\",\n",
        "    \"What are transitions\",\n",
        "    \"What is q0\",\n",
        "    \"What are transitions\",\n",
        "    \"Tell me more about the final state\",\n",
        "    \"Is the automaton deterministic\",\n",
        "    \"Transition from q5 to q7 exists\",\n",
        "    \"What is q1\",\n",
        "    \"What is the language\",\n",
        "    \"What are the arcs\",\n",
        "    \"Describe me briefly the automaton\",\n",
        "    \"What are the arcs\",\n",
        "    \"Transitions q4\",\n",
        "    \"Transitions q0\",\n",
        "    \"What is the language\",\n",
        "    \"How many states are there\",\n",
        "    \"How is the automaton represented\",\n",
        "    \"What is the language\",\n",
        "    \"What is the language\",\n",
        "    \"What is the language\",\n",
        "    \"Tell me about transitions\",\n",
        "    \"What is the alphabet\",\n",
        "    \"Describe me the automaton\",\n",
        "    \"Describe me the automaton\",\n",
        "    \"What is the language\",\n",
        "    \"What are transitions\",\n",
        "    \"What are transitions\",\n",
        "    \"What are transitions\",\n",
        "    \"What is the final state\",\n",
        "    \"What is the final state\",\n",
        "    \"How is the automaton represented\",\n",
        "    \"Describe me briefly the automaton\",\n",
        "    \"What are the states\",\n",
        "    \"What is an automaton\",\n",
        "    \"What is the alphabet\",\n",
        "    \"How is the automaton represented\",\n",
        "    \"What are transitions\",\n",
        "    \"Hello\",\n",
        "    \"Hello\",\n",
        "    \"Hello\",\n",
        "    \"How many states are there\",\n",
        "    \"How is the automaton represented\",\n",
        "    \"How is the automaton represented\",\n",
        "    \"Describe me briefly the automaton\",\n",
        "    \"What is an automaton\",\n",
        "    \"What is the initial state\",\n",
        "    \"What is the final state\",\n",
        "    \"Describe me the automaton\",\n",
        "    \"Describe me the automaton\",\n",
        "    \"What is an automaton\",\n",
        "    \"How many states\",\n",
        "    \"What are the arcs\",\n",
        "    \"What are the arcs\",\n",
        "    \"Tell me more about states\",\n",
        "    \"Transitions q0\",\n",
        "    \"Tell me the pattern\",\n",
        "    \"Tell me the pattern\",\n",
        "    \"Which are the transitions from q1\",\n",
        "    \"Which are the transitions from q2\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AigZ5KELO7G"
      },
      "outputs": [],
      "source": [
        "# Generation of vectors for input\n",
        "input_vectors = embedding_model.encode(inputs)\n",
        "\n",
        "# Creation of the FAISS index\n",
        "dimension = input_vectors.shape[1]\n",
        "index_io = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Conversion of vectors to numpy format\n",
        "input_vectors = np.array(input_vectors, dtype=np.float32)\n",
        "\n",
        "# Adding vectors to the index\n",
        "index_io.add(input_vectors)\n",
        "\n",
        "# Saving metadata (input and output)\n",
        "metadata_io = [{\"input\": inputs[i], \"output\": outputs[i]} for i in range(len(inputs))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4fuVOq6LaTc"
      },
      "outputs": [],
      "source": [
        "def search_io_vector_store(translation):\n",
        "    query_vector = embedding_model.encode([translation])[0].astype(np.float32)\n",
        "\n",
        "    # Number of results\n",
        "    k = 8\n",
        "\n",
        "    # Performing the search\n",
        "    distances, indices = index_io.search(query_vector.reshape(1, -1), k)\n",
        "\n",
        "    # Check if there are results\n",
        "    if len(indices[0]) == 0:\n",
        "        print(\"No results found.\")\n",
        "        return None\n",
        "    else:\n",
        "        # Retrieving the results\n",
        "        results = []\n",
        "        for idx in indices[0]:\n",
        "            result = metadata_io[idx]\n",
        "            results.append(result)\n",
        "            if len(results) >= k:\n",
        "                break\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XurXeYagQjj9"
      },
      "source": [
        "# Traduzione LNC Few Shots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrczpHahQ0JE"
      },
      "outputs": [],
      "source": [
        "def format_examples(example_list):\n",
        "    formatted_examples = \"\"\n",
        "    for example in example_list:\n",
        "        formatted_examples += f\"\"\"\n",
        "Original: \"{example['input']}\"\n",
        "Translation: {{\"Translation\": \"{example['output']}\"}}\"\"\"\n",
        "    return formatted_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDNypqDjpxuJ"
      },
      "outputs": [],
      "source": [
        "llama2PromptTemplate = lambda systemPrompt, userPrompt: f\"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "{systemPrompt}\n",
        "<</SYS>>\n",
        "\n",
        "{userPrompt} [/INST]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "its_nz35Qsaj"
      },
      "outputs": [],
      "source": [
        "systemPromptFewShots = \"\"\"\n",
        "You are an expert on finite state automata. Translate user inputs to a \\\n",
        "controlled natural language. Use precise, technical terminology, and format \\\n",
        "the response as a JSON object with the translation inside the 'Translation' field.\n",
        "\"\"\"\n",
        "\n",
        "userPromptFewShots = lambda text, example_list: f\"\"\"\n",
        "Please translate the following inputs into controlled natural language.\n",
        "Use the format provided in the examples:\n",
        "{format_examples(example_list)}\n",
        "Now, translate the new input using the same controlled natural language format.\n",
        "Format the response as a JSON object with the translation inside the 'Translation' field.\n",
        "Input: \"{text}\"\n",
        "Output:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLtmPxYIWqAF"
      },
      "outputs": [],
      "source": [
        "def extract_json_from_output(model_output):\n",
        "    start = model_output.find('{')\n",
        "    if start == -1:\n",
        "        print(\"Error: No opening brace found\")\n",
        "        return None\n",
        "\n",
        "    # Start counting braces\n",
        "    brace_count = 0\n",
        "    end = start\n",
        "    for i, char in enumerate(model_output[start:]):\n",
        "        if char == '{':\n",
        "            brace_count += 1\n",
        "        elif char == '}':\n",
        "            brace_count -= 1\n",
        "        if brace_count == 0:\n",
        "            end = start + i + 1\n",
        "            break\n",
        "\n",
        "    if brace_count != 0:\n",
        "        print(\"Error: Unbalanced braces\")\n",
        "        return None\n",
        "\n",
        "    json_str = model_output[start:end]\n",
        "\n",
        "    # Parse the JSON string into a Python dictionary\n",
        "    try:\n",
        "        json_output = json.loads(json_str)\n",
        "        return json_output\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Unable to decode JSON\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyCLbm-9Q40V"
      },
      "outputs": [],
      "source": [
        "def translate_CNL(user_input, few_shots):\n",
        "  model_output = call_model(llama2PromptTemplate(systemPromptFewShots, userPromptFewShots(user_input, few_shots)))\n",
        "  translation = extract_json_from_output(model_output)\n",
        "  if translation:\n",
        "    return translation['Translation'].replace(',', '')\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEvLFqRqJiSY"
      },
      "source": [
        "# Estrazione Espressioni Regolari e Ricerca per Pertinenza RE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3SBGDJWve4L"
      },
      "outputs": [],
      "source": [
        "# Function to extract regular expressions from an AIML file\n",
        "def extract_patterns(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        file_content = file.read()\n",
        "    pattern_regex = re.compile(r'<pattern>(.*?)</pattern>', re.DOTALL)\n",
        "    patterns = pattern_regex.findall(file_content)\n",
        "    # Filter patterns that consist solely of '*'\n",
        "    cleaned_patterns = [pattern for pattern in patterns if pattern.strip() != '*']\n",
        "    return cleaned_patterns\n",
        "\n",
        "# Function to preprocess the patterns\n",
        "def preprocess_pattern(pattern):\n",
        "    return re.sub(r'\\*', '', pattern)\n",
        "\n",
        "# Function to calculate similarity with wildcard\n",
        "def wildcard_similarity(pattern, query):\n",
        "    query = query.upper()\n",
        "    pattern = pattern.replace('*', '.*')\n",
        "    return bool(re.fullmatch(pattern, query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKC1EOnYN1qG"
      },
      "outputs": [],
      "source": [
        "# Initialization of the embedding model\n",
        "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Specify the path to your AIML file\n",
        "file_path = '/content/drive/My Drive/Llama2_Translation_LNC/novagraphABCv2.0.aiml.xml'\n",
        "\n",
        "# Extract regular expressions\n",
        "patterns = extract_patterns(file_path)\n",
        "\n",
        "# Preprocess the patterns\n",
        "preprocessed_patterns = [preprocess_pattern(pattern) for pattern in patterns]\n",
        "\n",
        "# Generate vectors for the preprocessed patterns\n",
        "pattern_vectors = embedding_model.encode(preprocessed_patterns)\n",
        "\n",
        "# Creation of the FAISS index for patterns\n",
        "dimension = pattern_vectors.shape[1]\n",
        "index_pattern = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Conversion of vectors to numpy format\n",
        "pattern_vectors = np.array(pattern_vectors, dtype=np.float32)\n",
        "\n",
        "# Adding vectors to the index\n",
        "index_pattern.add(pattern_vectors)\n",
        "\n",
        "# Saving metadata (regular expressions)\n",
        "metadata_pattern = [{\"pattern\": patterns[i], \"preprocessed_pattern\": preprocessed_patterns[i]} for i in range(len(patterns))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StmhTXEnMtxa"
      },
      "outputs": [],
      "source": [
        "# Function to search for the most relevant regular expression\n",
        "def search_regex_vector_store(query):\n",
        "    if query:\n",
        "        query_vector = embedding_model.encode([query])[0].astype(np.float32)\n",
        "        k = 10\n",
        "\n",
        "        # Perform the search\n",
        "        distances, indices = index_pattern.search(query_vector.reshape(1, -1), k)\n",
        "\n",
        "        # Retrieve candidates\n",
        "        candidate_patterns = [metadata_pattern[idx] for idx in indices[0]]\n",
        "\n",
        "        # Refine results using wildcard similarity\n",
        "        best_match = None\n",
        "        highest_similarity = 0.0\n",
        "        similarity = -1\n",
        "        exact_matches = []\n",
        "\n",
        "        for candidate in candidate_patterns:\n",
        "            pattern = candidate['pattern']\n",
        "            if wildcard_similarity(pattern, query):\n",
        "                similarity = 1.0  # Set similarity to 1 if there's an exact match\n",
        "                exact_matches.append((pattern, similarity))\n",
        "\n",
        "            if similarity > highest_similarity:\n",
        "                highest_similarity = similarity\n",
        "                best_match = pattern\n",
        "\n",
        "        # If there are exact matches, take the one with the highest similarity\n",
        "        if exact_matches:\n",
        "            exact_matches.sort(key=lambda x: x[1], reverse=True)\n",
        "            best_match, highest_similarity = exact_matches[0]\n",
        "\n",
        "        if best_match:\n",
        "            return best_match, highest_similarity\n",
        "        else:\n",
        "            # If no exact wildcard match is found, return the closest based on embedding\n",
        "            closest_pattern = candidate_patterns[0]['pattern']\n",
        "            closest_similarity = 1 / (1 + distances[0][0])\n",
        "            return closest_pattern, closest_similarity\n",
        "    else:\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJTXMO-igZsK"
      },
      "source": [
        "# Traduzione LNC - RE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yDIP5BGgfRw"
      },
      "outputs": [],
      "source": [
        "systemPrompt_AIML_LNC = \"\"\"\n",
        "You are an assistant that transforms questions into a controlled natural \\\n",
        "language format using a regular expression. Respond only with the JSON object \\\n",
        "containing the translation. Use the regular expression to ensure the structure is \\\n",
        "correct. Do not include any additional text.\n",
        "\"\"\"\n",
        "\n",
        "userPrompt_AIML_LNC = lambda translation, regular_expression: f\"\"\"\n",
        "Translate the input into a controlled natural language using the regular expression.\n",
        "Respond only with the JSON object.\n",
        "\n",
        "Example 1:\n",
        "Input: \"what is the initial stage\"\n",
        "Regular Expression: INITIAL STATE\n",
        "JSON Translation: {{\n",
        "  \"Translation\": \"what is the initial state\"\n",
        "}}\n",
        "\n",
        "Example 2:\n",
        "Input: \"tell me the transitions\"\n",
        "Regular Expression: TRANSITIONS\n",
        "JSON Translation: {{\n",
        " \"Translation\": \"transitions\"\n",
        "}}\n",
        "\n",
        "Example 3:\n",
        "Input: \"What the final state is?\"\n",
        "Regular Expression: * FINAL STATE\n",
        "JSON Translation: {{\n",
        "  \"Translation\": \"what is the final state\"\n",
        "}}\n",
        "\n",
        "Task:\n",
        "Input: {translation}\n",
        "Regular Expression: {regular_expression}\n",
        "Provide the JSON translation below:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBVRuhJLgeG9"
      },
      "outputs": [],
      "source": [
        "def translate_CNL_AIML(translation, regular_expression):\n",
        "  output = call_model(llama2PromptTemplate(systemPrompt_AIML_LNC, userPrompt_AIML_LNC(translation, regular_expression)))\n",
        "  extraction = extract_json_from_output(output)\n",
        "  if extraction:\n",
        "    return extraction['Translation'].replace(',', '')\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqA4Hqpqc4rA"
      },
      "source": [
        "# Esecuzione Codice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpzNj2BRRChW"
      },
      "outputs": [],
      "source": [
        "def execution(user_input):\n",
        "  print(\"Input: \", user_input)\n",
        "  # Check if it's already a relevant question, if there is a match with a regular expression\n",
        "  most_relevant_pattern, similarity_score = search_regex_vector_store(user_input)\n",
        "  print(\"PATTERN 1: \", most_relevant_pattern, \" Similarity Score: \", similarity_score)\n",
        "  if most_relevant_pattern and similarity_score is not None:\n",
        "    if similarity_score != 1:\n",
        "      # Search for few shots for relevance within the vector store\n",
        "      few_shots = search_io_vector_store(user_input)\n",
        "      # Generate a translation in LNC using the found few shots\n",
        "      translation = translate_CNL(user_input, few_shots)\n",
        "      print(\"TRANSLATION 1: \", translation)\n",
        "      # Search for the most relevant regular expression\n",
        "      if translation:\n",
        "        most_relevant_pattern, similarity_score = search_regex_vector_store(translation)\n",
        "        print(\"PATTERN 2: \", most_relevant_pattern, \" Similarity Score: \", similarity_score)\n",
        "        if most_relevant_pattern and similarity_score is not None and similarity_score < 0.8 and similarity_score > 0.1:\n",
        "          # Generate a second translation in LNC combining the AIML file and the first translation\n",
        "          final_output = translate_CNL_AIML(translation, most_relevant_pattern)\n",
        "          print(\"TRANSLATION 2: \", final_output)\n",
        "          if final_output:\n",
        "            return final_output\n",
        "          else:\n",
        "            return translation\n",
        "        else:\n",
        "          return translation\n",
        "      else:\n",
        "        return user_input\n",
        "    else:\n",
        "      return user_input\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ4kQAnKk8bD"
      },
      "source": [
        "# Server Flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHNYbvP3050k"
      },
      "outputs": [],
      "source": [
        "authtoken = \"2iNKZcAwjAZQZRfbHkWQCNZKThb_7DRmPbXvHG2L3CaVF8yfK\"\n",
        "ngrok.set_auth_token(authtoken)\n",
        "\n",
        "# Start ngrok on port 5000\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Ngrok URL: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EaOjGV7zNVi"
      },
      "outputs": [],
      "source": [
        "app = Flask(__name__)\n",
        "# Starts ngrok when the app is run\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/submit', methods=['POST'])\n",
        "def submit():\n",
        "    data = request.get_json()\n",
        "    user_input = data.get('input')\n",
        "\n",
        "    # Processing the input\n",
        "    print(\"Input\", user_input)\n",
        "    user_input = execution(user_input)\n",
        "    print(\"Output\", user_input)\n",
        "    # JSON response\n",
        "    response = {\n",
        "        \"status\": \"success\",\n",
        "        \"input_received\": user_input\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8WGr4ggxv3z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}